{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SESEMI.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/logan-cardinal/cs7641_lz/blob/main/Copy_of_SESEMI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKC-mc2itjx_"
      },
      "source": [
        "# Semi-Supervised Learning with SESEMI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6eMMU8d3hRb"
      },
      "source": [
        "This notebook accompanies the Medium article \"[Semi-Supervised Learning Demystified withÂ PyTorch](https://medium.com/@masonmcgough/semi-supervised-learning-demystified-with-pytorch-9656c14af031).\" Follow along with the post to use this notebook.\n",
        "\n",
        "In this notebook, I demonstrate the SESEMI technique described in \"[Exploring Self-Supervised Regularization for Supervised and Semi-Supervised Learning](https://arxiv.org/pdf/1906.10343.pdf)\" on the CIFAR-10 dataset using the handy pretrained ResNet model in `torchvision`. I encourage you to try this notebook with different amounts of labeled data to see the impact that semi-supervised regularization has on the model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYx8jluGtpBM"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sit4M75arwoz"
      },
      "source": [
        "import random\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhfV4NiitrRm"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YfREMg5_rIL"
      },
      "source": [
        "Here we define our labeled and unlabeled datasets. Since we are using CIFAR-10, a fully labeled dataset with 50000 images, we first need to subsample the labels in this dataset.\n",
        "\n",
        "The two classes `LabeledDataset` and `UnlabeledDataset` are subclasses of `torch.utils.data.Dataset` that provide useful iterators over labeled and unlabeled subsets of CIFAR-10, respectively. We do not instantiate these classes directly, instead using the `create_label_drop_datasets` function to do so. As the authors discuss in the paper, the `LabeledDataset` class repeats the subsampled labels so that its length and the length of `UnlabeledDataset` are the same. This allows the model to be trained jointly on both datasets.\n",
        "\n",
        "We also create a `SesemiTransform` class to apply a random augmentation to unlabeled examples and generate an auxiliary label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGnSoCpbr2EY"
      },
      "source": [
        "class SesemiTransform:\n",
        "    \"\"\"\n",
        "    Torchvision-style transform to apply SESEMI augmentation to image.\n",
        "    \"\"\"\n",
        "\n",
        "    classes = ('0', '90', '180', '270', 'hflip', 'vflip')\n",
        "\n",
        "    def __call__(self, x):\n",
        "        tf_type = random.randint(0, len(self.classes) - 1)\n",
        "        if tf_type == 0:\n",
        "            x = x\n",
        "        elif tf_type == 1:\n",
        "            x = transforms.functional.rotate(x, 90)\n",
        "        elif tf_type == 2:\n",
        "            x = transforms.functional.rotate(x, 180)\n",
        "        elif tf_type == 3:\n",
        "            x = transforms.functional.rotate(x, 270)\n",
        "        elif tf_type == 4:\n",
        "            x = transforms.functional.hflip(x)\n",
        "        elif tf_type == 5:\n",
        "            x = transforms.functional.rotate(x, 180)\n",
        "            x = transforms.functional.hflip(x)\n",
        "        return x, tf_type\n",
        "\n",
        "class LabeledDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Labeled training Dataset class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray, labels: list,\n",
        "            dataset_min_size: int = 0,\n",
        "            transform: Optional[transforms.Compose] = None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.min_size = dataset_min_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return max(len(self.labels), self.min_size)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> tuple:\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(f'{idx} is out-of-bounds for dataset (length: {len(self)})')\n",
        "        s_idx = idx % len(self.labels)\n",
        "        \n",
        "        data = self.data[s_idx]\n",
        "        labels = self.labels[s_idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data, labels\n",
        "\n",
        "class UnlabeledDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Unlabeled training Dataset class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data: np.ndarray,\n",
        "            transform: Optional[transforms.Compose] = None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.sesemi_transform = SesemiTransform()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> np.ndarray:\n",
        "        data = self.data[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        data, label = self.sesemi_transform(data)\n",
        "        return data, label\n",
        "\n",
        "def create_label_drop_datasets(dataset: Dataset, n_labels_to_keep: int,\n",
        "        seed: int = -1, transform: Optional[transforms.Compose] = None,\n",
        "        split: bool = False):\n",
        "    \"\"\"\n",
        "    Create labeled and unlabeled subsets from a given Dataset instance.\n",
        "    \"\"\"\n",
        "\n",
        "    data = dataset.data\n",
        "    labels = dataset.targets\n",
        "    n_data = len(labels)\n",
        "    assert n_data >= n_labels_to_keep, f'n_labels_to_keep ({n_labels_to_keep}) exceeds number of labels ({n_data})'\n",
        "\n",
        "    idxs = list(range(n_data))\n",
        "    if seed >= 0:\n",
        "        random.seed(seed)\n",
        "    random.shuffle(idxs)\n",
        "    selected_idxs = idxs[:n_labels_to_keep]\n",
        "    unselected_idxs = idxs[n_labels_to_keep:]\n",
        "    labeled_data = data[selected_idxs]\n",
        "    labels = [labels[_i] for _i in selected_idxs]\n",
        "    if split:\n",
        "        unlabeled_data = data[unselected_idxs]\n",
        "    else:\n",
        "        unlabeled_data = data\n",
        "    \n",
        "    labeled_dataset = LabeledDataset(labeled_data, labels,\n",
        "        dataset_min_size=len(unlabeled_data), transform=transform)\n",
        "    unlabeled_dataset = UnlabeledDataset(unlabeled_data, transform=transform)\n",
        "    return labeled_dataset, unlabeled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd8ShA0Ar53g"
      },
      "source": [
        "n_labels_to_keep = 5000\n",
        "batch_size = 64\n",
        "seed = 231\n",
        "n_epochs = 80\n",
        "n_batches_print = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKnN5spsr_Ig"
      },
      "source": [
        "sup_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "labeled_trainset, unlabeled_trainset = create_label_drop_datasets(trainset,\n",
        "    n_labels_to_keep=n_labels_to_keep, seed=seed, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "print(f'# labaled training:   {len(labeled_trainset):6d}')\n",
        "print(f'# unlabeled training: {len(unlabeled_trainset):6d}')\n",
        "print(f'#  testing:           {len(testset):6d}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbLmBrQbsAmB"
      },
      "source": [
        "labeled_trainloader = DataLoader(labeled_trainset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=2)\n",
        "unlabeled_trainloader = DataLoader(unlabeled_trainset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False,\n",
        "    num_workers=2)\n",
        "\n",
        "print(f'# labeled batches:   {len(labeled_trainloader):5d}')\n",
        "print(f'# unlabeled batches: {len(unlabeled_trainloader):5d}')\n",
        "print(f'#  testing batches:  {len(testloader):5d}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbtHWbMXtebP"
      },
      "source": [
        "## Display Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6SWLdcAvrIF"
      },
      "source": [
        "With our new dataloaders, let's generate a few examples to make sure they are doing what we think they should. First, we look at the labeled dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJjyK9tUsCG5"
      },
      "source": [
        "n_show_images = 4\n",
        "\n",
        "def imshow(img: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Display a single image.\n",
        "    \"\"\"\n",
        "\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(labeled_trainloader)\n",
        "images, labels = dataiter.next()\n",
        "imshow(torchvision.utils.make_grid(images[:n_show_images]))\n",
        "print(' '.join(f'{sup_classes[labels[j]]:5s}' for j in range(n_show_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WykkOOGGv0_8"
      },
      "source": [
        "Now we make sure the unlabeled dataloader is producing the labels we want. Note that the rotated images seem to match their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgd-XoWHsD4J"
      },
      "source": [
        "unsup_classes = unlabeled_trainset.sesemi_transform.classes\n",
        "dataiter = iter(unlabeled_trainloader)\n",
        "images, labels = dataiter.next()\n",
        "imshow(torchvision.utils.make_grid(images[:n_show_images]))\n",
        "print(' '.join(f'{unsup_classes[labels[j]]:5s}' for j in range(n_show_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1NffJGvtxJf"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fU7lqxjtylv"
      },
      "source": [
        "The SESEMI technique is model-agnostic and can be applied to any supervised learning task. The authors of [the paper](https://arxiv.org/pdf/1906.10343.pdf) experiment with three CNN architectures: Network-in-Network, a max-pooling ConvNet, and a wide residual network. We opt to go even simpler and use the standard ResNet you can import in `torchvision`.\n",
        "\n",
        "This model modifies the ResNet to accommodate two output layers, one for the supervised objective and another for the semi-supervised objective. In the `forward` method, we add an optional input argument `x_selfsup` so that we can accumulate gradients for labeled and unlabeled batches simultaneously during training. During inference, it is not necessary to provide a `x_selfsup` batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sig-26ndsGsh"
      },
      "source": [
        "class SesemiNet(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet backbone with two heads for SESEMI training.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_sup_classes: int,\n",
        "        n_unsup_classes: int,\n",
        "        pretrained: bool = True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.stem = torchvision.models.resnet18(pretrained=pretrained)\n",
        "        self.fc_out = 256\n",
        "        self.stem.fc = nn.Linear(self.stem.fc.in_features, self.fc_out)\n",
        "        self.sup_fc = nn.Linear(self.fc_out, n_sup_classes)\n",
        "        self.selfsup_fc = nn.Linear(self.fc_out, n_unsup_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, x_selfsup: Optional[torch.Tensor] = None):\n",
        "        x = self.stem(x)\n",
        "        x = self.sup_fc(x)\n",
        "        if x_selfsup is not None:\n",
        "            x_selfsup = self.stem(x_selfsup)\n",
        "            x_selfsup = self.selfsup_fc(x_selfsup)\n",
        "            return x, x_selfsup\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-sad3CFB7Az"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvndfKyVCEIR"
      },
      "source": [
        "Now we are ready to define our training loop. The `train` function is mostly boilerplate but note the lines that depict the forward pass and loss functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kQz4BQfsImJ"
      },
      "source": [
        "def train(\n",
        "    model: nn.Module,\n",
        "    labeled_trainloader: DataLoader,\n",
        "    unlabeled_trainloader: Optional[DataLoader] = None,\n",
        "    valloader: Optional[DataLoader] = None,\n",
        "    n_epochs: int = 2,\n",
        "    n_batches_print: int = 1000,\n",
        "    device: Optional[str] = None,\n",
        "    unsup_wt: float = 1.0\n",
        "):\n",
        "    \"\"\"\n",
        "    Execute SESEMI training loop.\n",
        "    \"\"\"\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    model.to(device)\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss_sum = 0.0\n",
        "        running_loss_sup = 0.0\n",
        "        running_loss_unsup = 0.0\n",
        "        dataloaders = zip(labeled_trainloader, [None] * len(labeled_trainloader))\\\n",
        "            if unlabeled_trainloader is None else zip(labeled_trainloader, unlabeled_trainloader)\n",
        "        for i, (sup_data, unsup_data) in enumerate(dataloaders, start=0):\n",
        "            optimizer.zero_grad()\n",
        "            sup_inputs, sup_labels = sup_data\n",
        "            sup_inputs = sup_inputs.to(device)\n",
        "            sup_labels = sup_labels.to(device)\n",
        "\n",
        "            if unsup_data is None:\n",
        "                sup_outputs = model(sup_inputs)\n",
        "                loss_unsup = 0.0\n",
        "            else:\n",
        "                unsup_inputs, unsup_labels = unsup_data\n",
        "                unsup_inputs = unsup_inputs.to(device)\n",
        "                unsup_labels = unsup_labels.to(device)\n",
        "                # forward pass through model with both data subsets\n",
        "                sup_outputs, unsup_outputs = model(sup_inputs, x_selfsup=unsup_inputs)\n",
        "                loss_unsup = unsup_criterion(unsup_outputs, unsup_labels)\n",
        "                running_loss_unsup += loss_unsup.item()\n",
        "            loss_sup = sup_criterion(sup_outputs, sup_labels)\n",
        "            # evaluate loss function\n",
        "            loss = loss_sup + unsup_wt * loss_unsup\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            iter_loss = loss_sup.item()\n",
        "            running_loss_sup += iter_loss\n",
        "            train_loss_sum += iter_loss\n",
        "\n",
        "            # print statistics\n",
        "            if i % n_batches_print == n_batches_print - 1:\n",
        "                if unsup_data is None:\n",
        "                    print(f'[{epoch + 1}, {i + 1:5d}] loss (sup): {running_loss_sup / n_batches_print:.4f}')\n",
        "                else:\n",
        "                    print(f'[{epoch + 1}, {i + 1:5d}] loss (sup): {running_loss_sup / n_batches_print:.4f} '\\\n",
        "                        f'loss (unsup): {running_loss_unsup / n_batches_print:.4f}')\n",
        "                running_loss_sup = 0.0\n",
        "                running_loss_unsup = 0.0\n",
        "        train_losses.append(train_loss_sum / len(labeled_trainloader))\n",
        "\n",
        "        # validation\n",
        "        if valloader is not None:\n",
        "            model.eval()\n",
        "            acc_values = []\n",
        "            acc_batchsize = []\n",
        "            running_loss = 0.0\n",
        "            for i, val_data in enumerate(valloader, start=0):\n",
        "                # forward + backward + optimize\n",
        "                optimizer.zero_grad()\n",
        "                val_inputs, val_labels = val_data\n",
        "                val_inputs = val_inputs.to(device)\n",
        "                val_labels = val_labels.to(device)\n",
        "                # forward pass of labeled data only for validation\n",
        "                val_outputs = model(val_inputs)\n",
        "                loss = sup_criterion(val_outputs, val_labels)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                acc, bsize = accuracy(val_outputs.data, val_labels, topk=(1,))\n",
        "                acc_values.append(acc[0].numpy())\n",
        "                acc_batchsize.append(bsize)\n",
        "            total_loss = running_loss / len(valloader)\n",
        "            total_acc = np.sum(np.array(acc_values) * np.array(acc_batchsize)) / np.sum(acc_batchsize)\n",
        "            print(f'Epoch: {epoch + 1}, loss (sup): {running_loss / len(valloader):.4f}, acc: {total_acc:.2f}')\n",
        "            val_losses.append(total_loss)\n",
        "            val_accs.append(total_acc)\n",
        "    print('Training Finished')\n",
        "    if valloader is None:\n",
        "        return train_losses\n",
        "    else:\n",
        "        return train_losses, val_losses, val_accs\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"\n",
        "    Calculate top-k accuracy for the given batch and its targets.\n",
        "    \"\"\"\n",
        "\n",
        "    output = output.cpu()\n",
        "    target = target.cpu()\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return (res, batch_size)\n",
        "\n",
        "def plot_losses(trainloss: list, valloss: Optional[list] = None,\n",
        "        title: str = 'Losses'):\n",
        "    \"\"\"\n",
        "    Display plot of training loss against validation loss.\n",
        "    \"\"\"\n",
        "\n",
        "    x = list(range(1, len(trainloss) + 1))\n",
        "    plt.plot(x, trainloss, 'b')\n",
        "    if valloss is not None:\n",
        "        plt.plot(x, valloss, 'r')\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAF_RGkwDfsN"
      },
      "source": [
        "### Supervised Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5thl_pP7DiGC"
      },
      "source": [
        "As a point of comparison, train the model first on the labeled subset only to get a baseline of performance without applying the SESEMI algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ7z9sNCsLLy"
      },
      "source": [
        "model = SesemiNet(len(sup_classes), len(unsup_classes), pretrained=True)\n",
        "\n",
        "sup_criterion = nn.CrossEntropyLoss()\n",
        "unsup_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "sup_train_losses, sup_val_losses, sup_val_accs = train(\n",
        "    model,\n",
        "    labeled_trainloader,\n",
        "    valloader=testloader,\n",
        "    n_epochs=n_epochs,\n",
        "    n_batches_print=n_batches_print)\n",
        "\n",
        "plot_losses(sup_train_losses, sup_val_losses, 'Loss without Self-supervision')\n",
        "print(f'Max accuracy: {np.max(sup_val_accs):.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGi6JnjeDq8b"
      },
      "source": [
        "### Semi-Supervised Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABXpE18HDrPQ"
      },
      "source": [
        "Noting the max accuracy resulting from the training procedure above, let us reinitialize the model and train again. The accuracy should be a considerable improvement over the previous, fully supervised attempt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51qIe1MxsM9S"
      },
      "source": [
        "model = SesemiNet(len(sup_classes), len(unsup_classes), pretrained=True)\n",
        "\n",
        "sup_criterion = nn.CrossEntropyLoss()\n",
        "unsup_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "unsup_train_losses, unsup_val_losses, unsup_val_accs = train(\n",
        "    model,\n",
        "    labeled_trainloader,\n",
        "    unlabeled_trainloader,\n",
        "    valloader=testloader,\n",
        "    n_epochs=n_epochs,\n",
        "    n_batches_print=n_batches_print)\n",
        "\n",
        "plot_losses(unsup_train_losses, unsup_val_losses, title='Loss with Self-supervision')\n",
        "print(f'Max accuracy: {np.max(unsup_val_accs):.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb52I23QGBwo"
      },
      "source": [
        "Although these results are far from state-of-the-art, they are impressive considering how little labeled data we used and how little we had to change to use the SESEMI algorithm. Feel free to try this using different proportions of labeled and unlabeled data, using different models, learning rate schedulers, different hyperparameters, and see if you can improve the results even more! "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation datasets\n",
        "image_datasets = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}"
      ],
      "metadata": {
        "id": "6kz68OET9sDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data in data_dir, must have folders named train and val, each with subfolder for each class"
      ],
      "metadata": {
        "id": "fefU7j2B-E_i"
      }
    }
  ]
}